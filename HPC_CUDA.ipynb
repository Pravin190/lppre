{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNGf8z4whfE8+FBDYDwbLrF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"14OSV7Gt8cVT"},"outputs":[],"source":["!pip install numba"]},{"cell_type":"code","source":["import numpy as np\n","from numba import cuda\n","\n","# CUDA kernel to perform vector addition\n","@cuda.jit\n","def vector_addition(a, b, result):\n","    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x\n","    if idx < len(a):\n","        result[idx] = a[idx] + b[idx]\n","\n","# User input for vector length\n","vector_length = int(input(\"Enter the length of the vectors: \"))\n","\n","# User input for vector elements\n","vector_a = np.zeros(vector_length, dtype=np.float32)\n","vector_b = np.zeros(vector_length, dtype=np.float32)\n","for i in range(vector_length):\n","    vector_a[i] = float(input(\"Enter the element of vector a at index {}: \".format(i)))\n","    vector_b[i] = float(input(\"Enter the element of vector b at index {}: \".format(i)))\n","\n","# Allocate memory on the GPU\n","device_vector_a = cuda.to_device(vector_a)\n","device_vector_b = cuda.to_device(vector_b)\n","device_result = cuda.device_array_like(vector_a)\n","\n","# Define the number of threads per block and the number of blocks\n","threads_per_block = 32\n","blocks_per_grid = (vector_length + (threads_per_block - 1)) // threads_per_block\n","\n","# Launch the kernel\n","vector_addition[blocks_per_grid, threads_per_block](device_vector_a, device_vector_b, device_result)\n","\n","# Copy the result back to the CPU\n","result = device_result.copy_to_host()\n","\n","# Print the result\n","print(\"Result:\", result)\n"],"metadata":{"id":"BXfcBP0z8xPZ"},"execution_count":null,"outputs":[]}]}